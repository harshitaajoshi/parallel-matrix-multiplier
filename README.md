# HPCAccel: Parallel Matrix Multiplier (OpenMP)
High-Performance Computing Project â€¢ Parallel Programming â€¢ Benchmarking â€¢ Speedup Analysis

This project implements a **parallelized matrix multiplication kernel** in C using **OpenMP**, along with a complete benchmarking workflow to measure multi-threaded performance and generate a **speedup curve**.

---

## ðŸš€ Features
- Multi-threaded matrix multiplication using **loop-level parallelism**
- Achieved **4Ã— speedup** compared to serial execution
- Benchmarked performance across **1â€“8 threads**
- Generated a **research-grade speedup plot** using Python + Matplotlib
- Evaluated:
  - Thread scheduling  
  - Workload balancing  
  - Cache locality  
  - Computeâ€“memory bottlenecks  

--- 

## ðŸ“ Project Structure
```
parallel-matrix-multiplier/
â”œâ”€â”€ matrix.c        # Parallel matrix multiplication using OpenMP
â”œâ”€â”€ plot.py         # Generates speedup visualization
â”œâ”€â”€ speedup.png     # Speedup graph (add after exporting)
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## âš™ï¸ Compile & Run

### **1. Compile with OpenMP**
```bash
/opt/homebrew/opt/llvm/bin/clang -Xclang -fopenmp matrix.c -o matrix \
    -L/opt/homebrew/opt/llvm/lib -lomp
```

### **2. Run with different thread counts**
```bash
export OMP_NUM_THREADS=1
./matrix

export OMP_NUM_THREADS=4
./matrix
```

---

## ðŸ“Š Benchmarking & Speedup Plot

Run:
```bash
python3 plot.py
```

### Speedup Formula
```
Speedup = T(1 thread) / T(n threads)
```

### Example Results
| Threads | Time (s) |
|--------|----------|
| 1 | 0.2477 |
| 2 | 0.1293 |
| 4 | 0.0757 |
| 6 | 0.0592 |
| 8 | 0.0594 |

### Speedup Interpretation

âš¡ The speedup curve shows **near-linear gains up to 4 threads**, with performance leveling off as the algorithm becomes **memory-bandwidth bound** â€” a classic HPC scaling pattern.

![Speedup Graph](speedup.png)

---

## ðŸ”¬ Parallel Performance Insights
This project demonstrates core concepts in HPC:

- Shared-memory parallelism  
- Thread-level parallel execution  
- Parallel efficiency vs. overhead  
- Diminishing returns beyond memory-bandwidth limits  
- Importance of cache locality in compute-heavy kernels  

---

## ðŸ“Œ Future Improvements
- Add **tiled (blocked)** matrix multiplication for better cache reuse  
- Explore **SIMD vectorization**  
- Compare **static vs dynamic OpenMP scheduling**  
- Benchmark larger problem sizes (N > 1000)

>>>>>>> 3504c2c (Update README formatting)
